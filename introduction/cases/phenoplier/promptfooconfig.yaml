prompts:
  - file://../../prompts/baseline.txt
  - file://../../prompts/candidate_with_metadata.txt
  - file://../../prompts/candidate.txt

# Default asserts applied to each test case below
defaultTest:
  # Make sure that output...
  assert:
    # ...starts with capital letter
    - type: python
      value: |
        description = "Starts with capital letter"
        type = "Formatting"
        score = 0.25
        
        res = output.strip()[0].isupper()
        
        return {
          "pass": res,
          "score": score if res else 0.0,
          "reason": "Passed" if res else "Failed",
          "assertion": {
            "value": description,
            "type": type,
          },
        }

    # ...ends with period
    - type: python
      value: |
        description = "Ends with a period"
        type = "Formatting"
        score = 0.25
        
        res = output.strip()[-1] == "."
        
        return {
          "pass": res,
          "score": score if res else 0.0,
          "reason": "Passed" if res else "Failed",
          "assertion": {
            "value": description,
            "type": type,
          },
        }

    # ...is a single paragraph
    - type: python
      value: |
        description = "Is a single paragraph"
        type = "Formatting"
        score = 0.25
        
        res = len(output.strip().split("\n")) == 1
        
        return {
          "pass": res,
          "score": score if res else 0.0,
          "reason": "Passed" if res else "Failed",
          "assertion": {
            "value": description,
            "type": type,
          },
        }

    # ...doesn't include manuscript title
    - type: python
      value: |
        description = "Doesn't include manuscript title"
        type = "Formatting"
        score = 0.25
        
        res = (context["vars"]["title"] not in output)
        
        return {
          "pass": res,
          "score": score if res else 0.0,
          "reason": "Passed" if res else "Failed",
          "assertion": {
            "value": description,
            "type": type,
          },
        }

    # ...doesn't reference authors, keywords, introduction, etc
    - type: python
      value: |
        description = "Doesn't reference authors, keywords, introduction, etc"
        type = "Formatting"
        score = 0.25
        
        keywords = [
          "authors",
          "Introduction:",
          "Keywords:",
          "References:",
        ]
        res = not any(kw in output for kw in keywords)
        
        return {
          "pass": res,
          "score": score if res else 0.0,
          "reason": "Passed" if res else "Failed",
          "assertion": {
            "value": description,
            "type": type,
          },
        }

    # ...is roughly same length as input
    - type: python
      value: |
        description = "Has roughly the same length as input"
        type = "Formatting"
        score = 0.25
        
        input = context["vars"]["content"]
        input_words = len(input.strip().split())
        output_words = len(output.strip().split())
        
        res = (output_words > 0.5 * input_words) and (output_words < 1.5 * input_words)
        
        return {
          "pass": res,
          "score": score if res else 0.0,
          "reason": "Passed" if res else "Failed",
          "assertion": {
            "value": description,
            "type": type,
          },
        }

# Make sure that output...
tests:
  # ...has no spelling or grammar errors
  - vars:
      test_description: Has no spelling errors
      title: file://./inputs/title.txt
      keywords: file://./inputs/keywords.txt
      content: file://./inputs/has_spelling_and_grammar_errors.md
    assert:
      - type: python
        value: |
          description = "Has no spelling errors"
          type = "Spelling/grammar"
          score = 2.0
          
          keywords = [
            "karry",
            "ekspression",
            "improoved",
            "studies has",
          ]
          res = not any(kw in output for kw in keywords)
          
          return {
            "pass": res,
            "score": score if res else 0.0,
            "reason": "Passed" if res else "Failed",
            "assertion": {
              "value": description,
              "type": type,
            },
          }

  # ...keeps most references to other articles and doesn't make them up
  - vars:
      test_description: Keeps most references to other articles and doesn't make them up
      title: file://./inputs/title.txt
      keywords: file://./inputs/keywords.txt
      content: file://./inputs/has_references_to_articles.md
    assert:
      - type: python
        value: |
          description = "Keeps most references to other articles"
          type = "Information accuracy"
          score = 2.0
          
          input = context["vars"]["content"]
          
          references = {
            "@doi:10.1038/nbt.3838",
            "@doi:10.1038/s41467-018-03751-6",
            "@doi:10.1126/science.aaz1776",
            "@doi:10.1186/s13040-020-00216-9",
            "@doi:10.1371/journal.pgen.1009482",
            "@doi:10.1038/ng.3506",
            "@doi:10.1371/journal.pgen.1007889",
            "@doi:10.1038/ng.3367",
            "@pmid:33931583",
            "@doi:10.1101/2021.10.21.21265225",
            "@pmid:31036433",
            "@doi:10.1186/s13059-021-02591-w",
            "@doi:10.1038/nn.4618",
          }
          
          # keep only references that are present in the input (this is needed because
          #  references might be removed from the input in some cases)
          references = [ref for ref in references if ref in input]
          
          count = len([ref for ref in references if ref in output])
          res = (count / len(references) > 0.50)
          
          return {
            "pass": res,
            "score": score if res else 0.0,
            "reason": "Passed" if res else "Failed",
            "assertion": {
              "value": description,
              "type": type,
            },
          }

      - type: python
        value: |
          description = "Does not make up references to other articles"
          type = "Information accuracy"
          score = 2.0
          
          import re
          
          input = context["vars"]["content"]
          
          references = {
            "@doi:10.1038/nbt.3838",
            "@doi:10.1038/s41467-018-03751-6",
            "@doi:10.1126/science.aaz1776",
            "@doi:10.1186/s13040-020-00216-9",
            "@doi:10.1371/journal.pgen.1009482",
            "@doi:10.1038/ng.3506",
            "@doi:10.1371/journal.pgen.1007889",
            "@doi:10.1038/ng.3367",
            "@pmid:33931583",
            "@doi:10.1101/2021.10.21.21265225",
            "@pmid:31036433",
            "@doi:10.1186/s13059-021-02591-w",
            "@doi:10.1038/nn.4618",
          }
          
          # keep only references that are present in the input (this is needed because
          #  references might be removed from the input in some cases)
          references = [ref for ref in references if ref in input]
          
          # capture current references in the output using a regex
          output_references = re.findall(r'@[^ ;\]]+', output)
          
          n_fake_refs = len([ref for ref in output_references if ref not in references])
          res = (n_fake_refs == 0)
          
          return {
            "pass": res,
            "score": score if res else 0.0,
            "reason": "Passed" if res else "Failed",
            "assertion": {
              "value": description,
              "type": type,
            },
          }

  # adheres to C-C-C by starting with context
  - vars:
      test_description: starts with context
      title: file://./inputs/title.txt
      keywords: file://./inputs/keywords.txt
      content: file://./inputs/doesnt_start_with_context.md
    assert:
      - type: python
        value: |
          description = "Starts with context"
          type = "Structure"
          score = 2.0
          
          # make sure TWAS is spelled out in the first two sentences
          first_two_sentences = ". ".join(output.split(". ")[:2]).lower()
          res = "transcription-wide association stud" in first_two_sentences
          
          return {
            "pass": res,
            "score": score if res else 0.0,
            "reason": "Passed" if res else "Failed",
            "assertion": {
              "value": description,
              "type": type,
            },
          }

  # adheres to C-C-C by ending with a conclusion
  - vars:
      test_description: ends with conclusion
      title: file://./inputs/title.txt
      keywords: file://./inputs/keywords.txt
      content: file://./inputs/doesnt_end_with_conclusion.md
    assert:
      - type: python
        value: |
          description = "Ends with conclusion"
          type = "Structure"
          score = 2.0
          
          # get last two sentences
          last_sentences = ". ".join(output.split(". ")[-2:]).lower()
          
          keywords = [
            "however",
            "nevertheless",
            "nonetheless",
            "limitation",
            "despite",
            "though",
            "even though",
          ]
          
          res = any(k in last_sentences for k in keywords)
          
          return {
            "pass": res,
            "score": score if res else 0.0,
            "reason": "Passed" if res else "Failed",
            "assertion": {
              "value": description,
              "type": type,
            },
          }
  